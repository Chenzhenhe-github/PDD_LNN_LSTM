{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77c49ee",
   "metadata": {},
   "source": [
    "# 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d594d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集参数设置\n",
    "training = 'training'#训练集文件夹名称\n",
    "group_num = [90,79,171] #按windows系统排列顺序\n",
    "group_name = ['control','mp','pd']\n",
    "mass_rate = 0.90 #m/z检出比例\n",
    "\n",
    "#测试集参数设置\n",
    "tolerance = 0.5 #质谱峰分辨率选择，不要改动，经测试0.5比0.3好！\n",
    "peak_int_learn = 0.01#根据峰强度选择质谱峰\n",
    "pvalues = 0.05 #p值筛选\n",
    "\n",
    "#数据集路径\n",
    "path = 'D:\\\\python test\\\\project83\\\\final\\\\pos5\\\\'+training+'\\\\'\n",
    "path_store = 'D:\\\\python test\\\\project83\\\\final\\\\pos5\\\\'+training+'_store\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c2d500",
   "metadata": {},
   "source": [
    "# 通过pyopenms进行m/z对齐和筛选"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "099e8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyopenms as oms\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "#数据质控，质谱峰去噪，去平头峰\n",
    "def noise_removal(prim,tolerance): \n",
    "    total = prim.values.tolist()\n",
    "    ref_total = total[1:]+[[0,0]]\n",
    "    new_total = [[r[0]-m[0],r[1]-m[1]] for r,m in zip(ref_total,total)]   \n",
    "    tf = [total[0]]\n",
    "    for new,ref,to in zip(new_total,ref_total,total):\n",
    "        if new[0] >= 0.5:        \n",
    "            tf = tf+[ref]\n",
    "        else:\n",
    "            if new[1]>=0:                      \n",
    "                tf = tf[:-1]+[ref]+[ref]\n",
    "            else:\n",
    "                tf = tf[:-1]+[to]+[to]\n",
    "    tf = [m for i,m in enumerate(tf) if m not in tf[:i]]            \n",
    "    return tf\n",
    "\n",
    "#生成openms数据格式\n",
    "def openms_data_format(mass,intensity,decimal=5):\n",
    "    #质谱保留\n",
    "    mz = np.round(mass.values,decimal)\n",
    "    mz_intensity = intensity.values\n",
    "    spectrum = oms.MSSpectrum()\n",
    "    spectrum.set_peaks([mz,mz_intensity])\n",
    "    spectrum.sortByPosition()\n",
    "    return spectrum\n",
    "\n",
    "#质量数对齐\n",
    "def mass_align(ref_spectrum,obs_spectrum,tolerance=0.5):\n",
    "    alignment = []\n",
    "    spa = oms.SpectrumAlignment()\n",
    "    p = spa.getParameters()\n",
    "    # use 0.5 Da tolerance (Note: for high-resolution data we could also use ppm \n",
    "    #by setting the is_relative_tolerance value to true)\n",
    "    p.setValue(\"tolerance\", tolerance)\n",
    "    p.setValue(\"is_relative_tolerance\", \"false\")\n",
    "    spa.setParameters(p)\n",
    "    # align both spectra\n",
    "    spa.getSpectrumAlignment(alignment, ref_spectrum, obs_spectrum)\n",
    "    return alignment\n",
    "\n",
    "#取质量数平均值_1\n",
    "def mass_calculation(re_spectrum,ob_spectrum,alignment,decimal=4):   \n",
    "    ref = [i[0] for i in alignment]\n",
    "    obs = [j[1] for j in alignment]\n",
    "    ref_mass = [re_spectrum.mass[i] for i in ref]\n",
    "    obs_mass = [ob_spectrum.mass[j] for j in obs]\n",
    "    ave_mass = np.round((np.array(ref_mass)+np.array(obs_mass))/2,decimal)\n",
    "    for i,j,q in zip(ref,obs,range(len(ave_mass))):\n",
    "        re_spectrum.iloc[i, 0] = ave_mass[q]\n",
    "        ob_spectrum.iloc[j, 0] = ave_mass[q]\n",
    "    return re_spectrum,ob_spectrum\n",
    "\n",
    "#按参比文件_2\n",
    "def mass_calculation_ref(re_spectrum,ob_spectrum,alignment,decimal=4):   \n",
    "    ref = [i[0] for i in alignment]\n",
    "    obs = [j[1] for j in alignment]\n",
    "    for i,j in zip(ref,obs):\n",
    "        ob_spectrum.iloc[j, 0] = re_spectrum.iloc[i, 0]         \n",
    "    return re_spectrum,ob_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4215534",
   "metadata": {},
   "source": [
    "# 初始文件的生成（默认采用第一个数据文件）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6616a4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "from jcamp import jcamp_readfile\n",
    "\n",
    "#读取文件列表2023年9月22日\n",
    "file_list = natsorted(os.listdir(path))\n",
    "column_list = [fst.split('.')[0] for fst in file_list]\n",
    "\n",
    "#增加文件初始值2023年9月22日\n",
    "name_list = file_list[1:]\n",
    "col_list = column_list[1:]\n",
    "\n",
    "#生成初始文件2023年9月22日\n",
    "first_file,first_column = file_list[0],column_list[0]\n",
    "prim = pd.read_excel(path+first_file)\n",
    "prim = noise_removal(prim,tolerance)\n",
    "prim = pd.DataFrame(prim,columns=['mass',first_column])\n",
    "#prim = prim[prim[first_column] >= peak_int_learn*max_peak].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa08be",
   "metadata": {},
   "source": [
    "# 添加剩余样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baa27b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#训练集生成20241124\n",
    "for name,col in zip(name_list,col_list):\n",
    "    #读取文件\n",
    "    indata = pd.read_excel(path+name) \n",
    "    denoise = noise_removal(indata,tolerance)# 去除噪声\n",
    "    framefile = pd.DataFrame(denoise,columns=['mass',col]) \n",
    "\n",
    "    #生成openms数据\n",
    "    ref_spectrum = openms_data_format(prim.mass,prim.iloc[:,1])\n",
    "    obs_spectrum = openms_data_format(framefile.mass,framefile.iloc[:,1])\n",
    "    alignment = mass_align(ref_spectrum,obs_spectrum,tolerance)\n",
    "\n",
    "    #数据整合\n",
    "    r_spectrum,o_spectrum = mass_calculation_ref(prim,framefile,alignment)\n",
    "    prim = pd.merge(prim,o_spectrum,how='outer',on='mass')#merge用好太不容易了\n",
    "    prim = prim.sort_values('mass',ascending=True).reset_index(drop=True)#merge用好太不容易了\n",
    "    \n",
    "#最终数据的生成\n",
    "outfile = prim.replace(0,np.nan).dropna(axis=0,how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26a777",
   "metadata": {},
   "source": [
    "# 数据统计分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49371ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集生成和保存\n",
    "prim_int = outfile\n",
    "\n",
    "# 数据统计值计算\n",
    "data_num = [0]\n",
    "for p in range(len(group_num)):\n",
    "    data_num.append(sum(group_num[:p+1]))\n",
    "\n",
    "minum_num = [round(m * mass_rate) for m in group_num]\n",
    "new_group_name = ['num_'+ name for name in group_name]\n",
    "\n",
    "#生成新的数据列\n",
    "for i,name in zip(range(len(data_num)-1),new_group_name):\n",
    "    prim_int[name] = prim_int.iloc[:,data_num[i]+1:data_num[i+1]+1].count(axis=1)\n",
    "\n",
    "#文件筛选\n",
    "total_file = prim_int[(prim_int[new_group_name[0]] >= minum_num[0])]    \n",
    "for name,mini in zip(new_group_name[1:],minum_num[1:]):\n",
    "    internal_file = prim_int[(prim_int[name] >= mini)]  \n",
    "    total_file = pd.merge(total_file,internal_file,how='outer') \n",
    "int_scd = total_file.copy().sort_values(by = 'mass').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30505dcb",
   "metadata": {},
   "source": [
    "# 数据预处理\n",
    "#SimpleImputer,NaN数据插补,可选\n",
    "#strategy=['mean','median','most_frequent']\n",
    "#数据正则化\n",
    "#'l1'特征值/征值绝对值之和、'l2'特征值/特征值绝对值平方和的开方、'max'特征值/特征值的最大值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9848e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer\n",
    "#-----------------数据预处理：和统计分析不同------------------\n",
    "makepip = make_pipeline(SimpleImputer(missing_values=np.nan,\\\n",
    "                                      strategy='median'),Normalizer(norm='l1'),StandardScaler())\n",
    "int_sc = int_scd[column_list].T\n",
    "treat = makepip.fit(int_sc)\n",
    "int_sc_norm = pd.DataFrame(treat.transform(int_sc).T,columns=column_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05abd691",
   "metadata": {},
   "source": [
    "# 统计分析和数据存储\n",
    "#数据统计分析No.2：组间比较和统计\n",
    "#9月16日修改，改用np.nanmean()求平均值\n",
    "#2025.2.19修改，增加ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37654efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "#对数据集进行拆分\n",
    "internal_list = []\n",
    "for i,name in zip(range(len(data_num)-1),new_group_name):\n",
    "    data_internal = int_sc_norm.iloc[:,data_num[i]:data_num[i+1]].T.values\n",
    "    internal_list.append(data_internal)\n",
    "\n",
    "#判定是否需要进行anova分析\n",
    "if len(group_num)>=3:\n",
    "    f_statistic, p_value = stats.f_oneway(*internal_list)\n",
    "    p_column = 'ANOVA'\n",
    "else:\n",
    "    s_statistic, p_value = stats.ttest_ind(*internal_list,equal_var=False)\n",
    "    p_column = 'ttest'\n",
    "    \n",
    "#筛选小于p值的m/z\n",
    "p_value = pd.DataFrame(p_value,columns = [p_column])\n",
    "int_scf = pd.concat([int_scd,p_value],axis=1)\n",
    "int_F = int_scf[(int_scf[p_column] <= 0.05)]\n",
    "int_F_sort = int_F.sort_values(by = ['mass'])\n",
    "\n",
    "#数据存储\n",
    "int_F_sort.to_excel(path_store+training+'_screened_int.xlsx',index=False)\n",
    "int_scf.to_excel(path_store+training+'_int.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661a47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
